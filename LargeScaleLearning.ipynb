{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Notebook\n",
    "\n",
    "- [**Kaggle Housing Dataset**](https://www.kaggle.com/ananthreddy/housing)\n",
    "- Implement linear regression using:\n",
    "    1. **Batch** Gradient Descent\n",
    "    2. **Stochastic** Gradient Descent\n",
    "    3. **Mini-batch** Gradient Descent\n",
    "    \n",
    "**Note**: _Trying to implement using **PyTorch** instead of numpy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banner(msg, _verbose=1):\n",
    "    if not _verbose:\n",
    "        return\n",
    "    print(\"-\"*80)\n",
    "    print(msg.upper())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Housing.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(string):\n",
    "    return int('yes' in string)\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(convert_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "y = data[:, 0]\n",
    "\n",
    "print(\"X: \", X.shape)\n",
    "print(\"y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = map(torch.from_numpy, train_test_split(X, y, test_size=0.2))\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_valid: \", X_valid.shape)\n",
    "print(\"y_valid: \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, X_train, y_train, X_valid, y_valid):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        \n",
    "        self.Theta = torch.randn((X_train.shape[1]+1)).type(type(X_train))\n",
    "        \n",
    "    def _add_bias(self, tensor):\n",
    "        bias = torch.ones((tensor.shape[0], 1)).type(type(tensor))\n",
    "        return torch.cat((bias, tensor), 1)\n",
    "        \n",
    "    def _forward(self, tensor):\n",
    "        return torch.matmul(\n",
    "            self._add_bias(tensor),\n",
    "            self.Theta\n",
    "        ).view(-1)\n",
    "    \n",
    "    def forward(self, train=True):\n",
    "        if train:\n",
    "            return self._forward(self.X_train)\n",
    "        else:\n",
    "            return self._forward(self.X_valid)\n",
    "    \n",
    "    def _cost(self, X, y):\n",
    "        y_hat = self._forward(X)\n",
    "        mse = torch.sum(torch.pow(y_hat - y, 2))/2/X.shape[0]\n",
    "        return mse\n",
    "    \n",
    "    def cost(self, train=True):\n",
    "        if train:\n",
    "            return self._cost(self.X_train, self.y_train)\n",
    "        else:\n",
    "            return self._cost(self.X_valid, self.y_valid)\n",
    "        \n",
    "    def batch_update_vectorized(self):\n",
    "        m, _ = self.X_train.size()\n",
    "        return torch.matmul(\n",
    "                self._add_bias(self.X_train).transpose(0, 1),\n",
    "                (self.forward() - self.y_train)\n",
    "            ) / m\n",
    "    \n",
    "    def batch_update_iterative(self):\n",
    "        m, _ = self.X_train.size()\n",
    "        update_theta = None\n",
    "        X = self._add_bias(self.X_train)\n",
    "        for i in range(m):\n",
    "            if type(update_theta) == torch.DoubleTensor:\n",
    "                update_theta += (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n",
    "            else:\n",
    "                update_theta = (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n",
    "        return update_theta/m\n",
    "        \n",
    "    \n",
    "    def batch_train(self, tolerance=0.01, alpha=0.01):\n",
    "        converged = False\n",
    "        prev_cost = self.cost()\n",
    "        init_cost = prev_cost\n",
    "        num_epochs = 0\n",
    "        while not converged:\n",
    "            self.Theta = self.Theta - alpha * self.batch_update_vectorized()\n",
    "            cost = self.cost()\n",
    "            if (prev_cost - cost) < tolerance:\n",
    "                converged = True\n",
    "            prev_cost = cost\n",
    "            num_epochs += 1\n",
    "        banner(\"Batch\")\n",
    "        print(\"\\tepochs: \", num_epochs)\n",
    "        print(\"\\tcost before optim: \", init_cost)\n",
    "        print(\"\\tcost after optim: \", cost)\n",
    "        print(\"\\ttolerance: \", tolerance)\n",
    "        print(\"\\talpha: \", alpha)\n",
    "            \n",
    "    def stochastic_train(self, tolerance=0.01, alpha=0.01):\n",
    "        converged = False\n",
    "        m, _ = self.X_train.size()\n",
    "        X = self._add_bias(self.X_train)\n",
    "        init_cost = self.cost()\n",
    "        num_epochs=0\n",
    "        while not converged:\n",
    "            prev_cost = self.cost()\n",
    "            for i in range(m):\n",
    "                self.Theta = self.Theta - alpha * (self._forward(self.X_train[i].view(1, -1)) - self.y_train[i]) * X[i]\n",
    "            cost = self.cost()\n",
    "            if prev_cost-cost < tolerance:\n",
    "                converged=True\n",
    "            num_epochs += 1\n",
    "        banner(\"Stochastic\")\n",
    "        print(\"\\tepochs: \", num_epochs)\n",
    "        print(\"\\tcost before optim: \", init_cost)\n",
    "        print(\"\\tcost after optim: \", cost)\n",
    "        print(\"\\ttolerance: \", tolerance)\n",
    "        print(\"\\talpha: \", alpha)\n",
    "        \n",
    "    def mini_batch_train(self, tolerance=0.01, alpha=0.01, batch_size=8):\n",
    "        converged = False\n",
    "        m, _ = self.X_train.size()\n",
    "        X = self._add_bias(self.X_train)\n",
    "        init_cost = self.cost()\n",
    "        num_epochs=0\n",
    "        while not converged:\n",
    "            prev_cost = self.cost()\n",
    "            for i in range(0, m, batch_size):\n",
    "                self.Theta = self.Theta - alpha / batch_size * torch.matmul(\n",
    "                    X[i:i+batch_size].transpose(0, 1),\n",
    "                    self._forward(self.X_train[i: i+batch_size]) - self.y_train[i: i+batch_size]\n",
    "                )\n",
    "            cost = self.cost()\n",
    "            if prev_cost-cost < tolerance:\n",
    "                converged=True\n",
    "            num_epochs += 1\n",
    "        banner(\"Stochastic\")\n",
    "        print(\"\\tepochs: \", num_epochs)\n",
    "        print(\"\\tcost before optim: \", init_cost)\n",
    "        print(\"\\tcost after optim: \", cost)\n",
    "        print(\"\\ttolerance: \", tolerance)\n",
    "        print(\"\\talpha: \", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = LinearRegression(X_train, y_train, X_valid, y_valid)\n",
    "l.mini_batch_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = LinearRegression(X_train, y_train, X_valid, y_valid)\n",
    "l.stochastic_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = LinearRegression(X_train, y_train, X_valid, y_valid)\n",
    "l.batch_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
